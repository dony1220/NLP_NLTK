{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.2-cp311-cp311-win_amd64.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gensim) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gensim) (1.11.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gensim) (6.4.0)\n",
      "Downloading gensim-4.3.2-cp311-cp311-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/24.0 MB 975.2 kB/s eta 0:00:25\n",
      "   --- ------------------------------------ 2.2/24.0 MB 20.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.3/24.0 MB 40.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 11.9/24.0 MB 108.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 16.0/24.0 MB 110.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 17.8/24.0 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 18.2/24.0 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.6/24.0 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 43.7 MB/s eta 0:00:00\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Nsmc 데이터 로드\n",
    "train_df = pd.read_csv('./data/ratings_train.csv')\n",
    "train_df.dropna(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본 전처리 과정\n",
    "\n",
    "1. 한글만 남김 (특수 기호 제거)\n",
    "2. 명사만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙   진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠   포스터보고 초딩영화줄    오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼   솔직히 재미는 없다  평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙   진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠   포스터보고 초딩영화줄    오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼   솔직히 재미는 없다  평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "train_df['document'] = train_df['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣]\", \" \", regex=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       아 더빙   진짜 짜증나네요 목소리\n",
       "1                         흠   포스터보고 초딩영화줄    오버연기조차 가볍지 않구나\n",
       "2                                         너무재밓었다그래서보는것을추천한다\n",
       "3                             교도소 이야기구먼   솔직히 재미는 없다  평점 조정\n",
       "4         사이몬페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어보이기만 했던 커스틴 ...\n",
       "                                ...                        \n",
       "149995                                  인간이 문제지   소는 뭔죄인가  \n",
       "149996                                        평점이 너무 낮아서   \n",
       "149997                      이게 뭐요  한국인은 거들먹거리고 필리핀 혼혈은 착하다 \n",
       "149998                          청춘 영화의 최고봉 방황과 우울했던 날들의 자화상\n",
       "149999                             한국 영화 최초로 수간하는 내용이 담긴 영화\n",
       "Name: document, Length: 149995, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "train_df['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 정의\n",
    "stopwords = ['의', '가', '이', '은', '들', '는', '좀', '을', '를', '는', '으로']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['데', '너', '리스', '타르', '가르다', '나다', '용의', '주인', '이', '되다', '싶다', '누', '이랑', '근친상간', '이나', '하다', '다니다', '소설', '속', '에선', '제일', '멋지다', '놈', '이', '자', '이', '메', '라', '니스', '터', '이다', '드라마', '속', '에선', '드래곤', '용', '이', '제일', '멋지다', '웃음', '감독', '님', '토르', '다크', '월드', '는', '말', '아', '잡수다', '기본', '선방', '은', '하다', ['데', '너', '리스', '타르', '가르다', '나다', '용의', '주인', '되다', '싶다', '누', '이랑', '근친상간', '이나', '하다', '다니다', '소설', '속', '에선', '제일', '멋지다', '놈', '자', '메', '라', '니스', '터', '이다', '드라마', '속', '에선', '드래곤', '용', '제일', '멋지다', '웃음', '감독', '님', '토르', '다크', '월드', '말', '아', '잡수다', '기본', '선방', '하다']]\n",
      "-------------\n",
      "[['더빙', '진짜', '목소리'], ['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기'], ['무재', '밓었', '다그', '래서', '추천'], ['교도소', '이야기', '구먼', '재미', '평점', '조정'], ['몬페', '의', '연기', '영화', '스파이더맨', '커스틴', '던스트'], ['막', '걸음', '마', '세', '초등학교', '학년', '생인', '영화', '반개', '움'], ['원작', '긴장감', '제대로'], ['별', '반개', '욕', '이응경', '길용우', '생활', '년', '정말', '발', '해도', '그것', '납치', '감금', '반복', '반복', '드라마', '가족', '연기', '사람', '네'], ['액션', '재미', '몇', '영화'], ['왜케', '평점', '꽤', '볼', '데', '헐리우드'], ['인피니트', '짱', '진짜'], ['볼때', '년대', '향수', '자극', '허진호', '감성', '절제', '멜로', '달인'], ['울면', '손', '횡단보도', '때', '뻔', '이범수', '연기'], ['로만', '자꾸', '그', '사람', '것'], ['취향', '존중', '다지', '진짜', '내생', '극장', '영화', '가장', '노잼', '노', '감동', '임', '스토리', '어거지', '감동', '어거지'], ['냥', '매번', '긴장', '재밋음'], ['사람', '바스코', '이기', '락스', '코', '바비', '이기', '아이돌', '그냥', '안달', '것'], ['굿바이', '레닌', '표절', '것', '이해', '왜', '뒤', '갈수록', '재미'], ['이건', '정말', '깨알', '캐스팅', '질퍽', '용구성', '버무러진', '깨알', '일드'], ['약탈', '위', '변명', '놈', '놈', '절대', '걸'], ['나름', '뜻', '듯', '그냥', '학생', '선생', '영화', '절대'], ['건'], ['음식', '영화', '도', '바베트', '만찬', '바베트', '만찬', '이야기', '음식', '재미', '이건', '볼', '음식', '별로', '핀란드', '풍경', '할랫', '그것', '별로'], ['절대', '영화', '수작', '는걸'], ['주제', '중반'], ['짤랐을꺼', '납득', '수', '꼭'], ['고추'], ['카밀라', '벨', '발연기'], ['재밋는뎅'], ['센스', '연출', '캐스팅', '년대', '향수', '점'], ['엄포스', '위력', '다시', '한번', '적', '남', '꽃', '검사', '연기', '정말', '완전', '명품', '드라마'], ['졸', '쓰레기', '도안', '시간'], ['점', '왜'], ['내', '죄인', '죄인'], ['이', '드라마', '인생', '최고'], ['패션', '대한', '열정', '안나', '윈', '투어'], ['키이라', '나이틀리', '연기', '대체', '정신장애', '틱장애'], ['원작', '정신', '유령'], ['포스터', '관객', '명'], ['이', '영화', '왜', '평가'], ['매력', '영화'], ['알바생', '내용', '하나', '완전', '별', '영화', '내', '시간', '움', '완전', '낚임'], ['서리', '이'], ['정말', '맘', '또', '또', '방법'], ['윤제문', '배우', '발견', '탈', '미소', '머금', '음악', '조금', '점', '평점', '점'], ['평점', '속지', '시간', '낭비', '돈', '낭비', '임'], ['리얼리티', '공감', '안', '간다', '이민기', '캐릭터', '정신의학', '분노조절', '장애', '초기', '증상', '툭하면', '사람', '패', '욕', '물건', '파손', '조금', '바', '초반', '가면', '갈수록', '이민기', '정신', '상태', '공감', '불가'], ['마이너스', '왜', '뮤비', '보고', '영화', '수준', '알', '북한', '돈'], ['난', '우리', '영화', '사랑'], ['데', '리스', '타르', '용의', '주인', '누', '근친상간', '소설', '속', '제일', '놈', '자', '메', '니스', '터', '드라마', '속', '드래곤', '용', '이', '제일', '웃음', '감독', '토르', '다크', '월드', '말', '기본', '선방']]\n"
     ]
    }
   ],
   "source": [
    "# 형태소 분석 및 불용어 제거하여 데이터 전처리하기\n",
    "# 1. 문서 하나씩 읽어오기 (50개만)\n",
    "# 2. 문서에 okt 형태소 분석 적용 (morphs함수, stem=True 변경)\n",
    "# 3. 불용어 제거\n",
    "# 4. tokenized_words 리스트(문서 별 형태소 추출): [[words, words, words], [words, words, words]]\n",
    "# 5. sentence_nouns 리스트(모든 명사 리스트): [noun, noun, noun, noun]\n",
    "okt = Okt()\n",
    "\n",
    "tokenized_words, sentence_nouns = [] , []\n",
    "\n",
    "for i in train_df['document'][:50]:\n",
    "    #문서 별 형태소 추출\n",
    "    tokenized_words = okt.morphs(i, stem=True)\n",
    "    stopwords_removed_sentence = [word for word in tokenized_words if not word in stopwords]\n",
    "    tokenized_words.append(stopwords_removed_sentence)\n",
    "    #명사만 추출\n",
    "    nouns = okt.nouns(i)\n",
    "    sentence_nouns.append(nouns)\n",
    "\n",
    "print(tokenized_words)\n",
    "print(\"-------------\")\n",
    "print(sentence_nouns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자연어처리에서 데이터 EDA하기\n",
    "\n",
    "1. 텍스트 데이터의 수를 기준(통계적 수치 확인)  \n",
    "    1. 텍스트 길이의 최대, 최소, 중앙값, 평균값을 확인  \n",
    "        - 최대값 : 임베딩을 할 때, max_len 파라미터에 대한 값을 설정\n",
    "    2. 각 품사별 데이터 수 확인\n",
    "        - 대부분은 명사가 많이 사용됨\n",
    "        - 만약 하드웨어등의 사양이 낮아 문제가 되는 경우, 명사만 분석을 하기 위해 데이터 수 확인  \n",
    "  \n",
    "2. 용어(텍스트) 기준  \n",
    "    1. 불용어 사용할 단어\n",
    "    2. 유의어들 확인하기 위한 원문 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 긴 문서 길이 (단어기준) : 47, 가장 짧은 문서 길이 (단어기준) : 1\n",
      "가장 긴 문서 길이 (명사기준) : 29, 가장 짧은 문서 길이 (명사기준) : 1\n"
     ]
    }
   ],
   "source": [
    "# 리뷰의 최대 길이\n",
    "word_len = [len(l) for l in tokenized_words]\n",
    "nouns_len = [len(l) for l in sentence_nouns]\n",
    "\n",
    "print(f\"가장 긴 문서 길이 (단어기준) : {max(word_len)}, 가장 짧은 문서 길이 (단어기준) : {min(word_len)}\")\n",
    "\n",
    "print(f\"가장 긴 문서 길이 (명사기준) : {max(nouns_len)}, 가장 짧은 문서 길이 (명사기준) : {min(nouns_len)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# '''\n",
    "# 결과\n",
    "# 가장 긴 문서 길이 : 95, 가장 짧은 단어 길이 : 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 가장 긴 명사 길이 : 66, 가장 짧은 명사 길이 : 0\n",
    "# '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec 훈련\n",
    "\n",
    "vector_size = 워드 벡터의 특징 값, 즉 임베딩 된 벡터의 차원  \n",
    "window = 컨텐스트 윈도우 크기  \n",
    "min_count = 단어 최소 빈도 수 제한(빈도가 적은 단어들을 학습하지 않도록 하는 기준)  \n",
    "workers = 학습을 위한 프로세스 수 (workers로 설정을 하거나 혹은 multiprocessing으로 병렬처리)  \n",
    "sg = 0 (CBOW) , 1 (Skip-gram)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec 모델 훈련하기\n",
    "model_cbow = Word2Vec(tokenized_words, vector_size=100, window=5, min_count=5,\n",
    "         workers=4, sg=0)\n",
    "\n",
    "\n",
    "model_skipgram = Word2Vec(tokenized_words, vector_size=100, window=5, min_count=5,\n",
    "         workers=4, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완성된 임베딩 매트릭스의 크기 확인(단어수, 차원수)\n",
    "print(model_cbow.wv.vectors.shape)\n",
    "print(model_skipgram.wv.vectors.shape)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "결과\n",
    "(15204, 100)\n",
    "(15204, 100)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 저장 방법\n",
    "\n",
    "1. 재훈련 없이 모델만 사용\n",
    "2. 재훈련을 할 수 있도록 임베딩에 대한 기본 정보를 함께 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 방법 1 : 재훈련을 하지 않는 경우\n",
    "## Ram에 로드하지 않고도 디스크나 네트워크에서 데이터를 즉시 읽어 반복할 수 있음\n",
    "## 모델 inference 에서 활용하면 좋음\n",
    "\n",
    "model_cbow.wv.save_word2vec_format('./data/kor_w2v_cbow')\n",
    "model_skipgram.wv.save_word2vec_format('./data/kor_w2v_skipgram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 방법1의 결과를 다시 로드해서 사용\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model_cbow_kv = KeyedVectors.load_word2vec_format('./data/kor_w2v_cbow')\n",
    "model_skipgram_kv = KeyedVectors.load_word2vec_format('./data/kor_w2v_skipgram')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('김혜수', 0.9176788330078125), ('한석규', 0.9148017168045044), ('황정민', 0.9026427268981934), ('안성기', 0.9024378657341003), ('덴젤', 0.8985658288002014)]\n",
      "[('한석규', 0.8817006349563599), ('문채원', 0.8791478276252747), ('안성기', 0.875672459602356), ('이주승', 0.862896740436554), ('조재현', 0.8615970015525818)]\n"
     ]
    }
   ],
   "source": [
    "# 특정 단어를 중심으로 유사한 단어 확인하기\n",
    "print(model_cbow_kv.most_similar(\"설경구\", topn=5))\n",
    "print(model_skipgram_kv.most_similar(\"설경구\", topn=5))\n",
    "#비슷한 단어를 추출하고, 유사도를 측정해준다!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 방법2 : 재훈련 가능한 모델\n",
    "\n",
    "model_cbow.save('./data/kor_w2v_cbow.model')\n",
    "model_skipgram.save('./data/kor_w2v_skipgram.model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "## 모델에 vocab 정보 등이 함께 저장된 결과를 로드함\n",
    "\n",
    "\n",
    "model_cbow_model = Word2Vec.load('./data/kor_w2v_cbow.model')\n",
    "model_skipgram_model = Word2Vec.load('./data/kor_w2v_skipgram.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('추강', 0.8743879199028015), ('뻐', 0.8570932745933533), ('Good', 0.8364663124084473), ('파이팅', 0.8234995007514954), ('Very', 0.8139578700065613), ('홧팅', 0.8117495775222778), ('역쉬', 0.8104362487792969), ('good', 0.80389404296875), ('강', 0.8033527731895447), ('짱짱맨', 0.8007481694221497)]\n",
      "[('추강', 0.8798815608024597), ('강츄', 0.7837347388267517), ('개강', 0.7676759362220764), ('원츄', 0.7452652454376221), ('추하다', 0.7406888008117676), ('강추', 0.7364051938056946), ('요강', 0.734803318977356), ('몬스타', 0.7328289151191711), ('굿굿굿', 0.7328191995620728), ('Good', 0.7307455539703369)]\n"
     ]
    }
   ],
   "source": [
    "# 특정 단어를 중심으로 유사한 단어 확인하기\n",
    "print(model_cbow_model.wv.most_similar(\"추\"))\n",
    "print(model_skipgram_model.wv.most_similar(\"추\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('이기광', 0.909092366695404),\n",
       " ('송재림', 0.9026839733123779),\n",
       " ('지현', 0.9005348682403564),\n",
       " ('소희', 0.8992056846618652),\n",
       " ('승호', 0.8982767462730408),\n",
       " ('정용화', 0.8953133225440979),\n",
       " ('두준', 0.8944463729858398),\n",
       " ('박지성', 0.8944243788719177),\n",
       " ('찬열', 0.8933141827583313),\n",
       " ('**', 0.8929346799850464)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두 단어 간의 유사도 파악하기\n",
    "\n",
    "model_skipgram_model.wv.most_similar('웅')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전에 없는 경우 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('김기덕', 0.6263550519943237),\n",
       " ('역량', 0.6012963652610779),\n",
       " ('제작자', 0.5873256921768188),\n",
       " ('장진', 0.5859318971633911),\n",
       " ('박찬욱', 0.5739709138870239),\n",
       " ('자질', 0.5664553046226501),\n",
       " ('작가', 0.5588863492012024),\n",
       " ('오우삼', 0.5537692308425903),\n",
       " ('봉준호', 0.5470575094223022),\n",
       " ('임권택', 0.542576253414154)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여러 단어와 유사한 embedding 가져오기\n",
    "\n",
    "model_skipgram_model.wv.most_similar(positive=['여자', '감독'], negative=['남자'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('김기덕', 0.6410436630249023),\n",
       " ('장진', 0.6115475296974182),\n",
       " ('봉준호', 0.5934121608734131),\n",
       " ('천재', 0.5925087928771973),\n",
       " ('영화감독', 0.5785976648330688),\n",
       " ('핀처', 0.5773937106132507),\n",
       " ('린치', 0.5688480138778687),\n",
       " ('능력', 0.5647576451301575),\n",
       " ('서극', 0.5586300492286682),\n",
       " ('여균동', 0.5543100833892822)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosmul 사용해 보기\n",
    "model_skipgram_model.wv.most_similar(positive=['남자', '감독'], negative=['여자'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('놈', 0.515007734298706),\n",
       " ('성격', 0.5138322710990906),\n",
       " ('교수', 0.5029890537261963),\n",
       " ('남자', 0.4960451126098633),\n",
       " ('남편', 0.49485912919044495),\n",
       " ('본인', 0.49312278628349304),\n",
       " ('짓', 0.49199169874191284),\n",
       " ('자기', 0.49119845032691956),\n",
       " ('직업', 0.49061641097068787),\n",
       " ('목사', 0.4866125285625458)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그룹간의 유사도 측정\n",
    "model_cbow_model.wv.most_similar_cosmul(positive=['여자', '감독'])\n",
    "\n",
    "print(model_skipgram_model.wv.n_similarity(['남자', '배우'], ['여자', '감독']))\n",
    "\n",
    "print(model_skipgram_model.wv.n_similarity(['남자', '배우'], ['남자', '감독']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선생님\n",
      "음식\n"
     ]
    }
   ],
   "source": [
    "# 가장 유사하지 않은 단어를 추출\n",
    "print(model_skipgram_model.wv.doesnt_match(['영화', '드라마', '감독', '선생님']))\n",
    "\n",
    "print(model_skipgram_model.wv.doesnt_match(['냉장고', '음식', '밥', '당근']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존에 학습된 모델 확인 및 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fasttext-wiki-news-subwords-300',\n",
       " 'conceptnet-numberbatch-17-06-300',\n",
       " 'word2vec-ruscorpora-300',\n",
       " 'word2vec-google-news-300',\n",
       " 'glove-wiki-gigaword-50',\n",
       " 'glove-wiki-gigaword-100',\n",
       " 'glove-wiki-gigaword-200',\n",
       " 'glove-wiki-gigaword-300',\n",
       " 'glove-twitter-25',\n",
       " 'glove-twitter-50',\n",
       " 'glove-twitter-100',\n",
       " 'glove-twitter-200',\n",
       " '__testing_word2vec-matrix-synopsis']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "from pprint import pprint as pp\n",
    "\n",
    "\n",
    "list(gensim.downloader.info()['models'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# vector load (로드 시간 있음)\n",
    "\n",
    "glove_vectors_25 = api.load('glove-twitter-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('facebook', 0.9480050802230835),\n",
       " ('tweet', 0.9403423070907593),\n",
       " ('fb', 0.9342359900474548),\n",
       " ('instagram', 0.9104824066162109),\n",
       " ('chat', 0.8964963555335999),\n",
       " ('hashtag', 0.8885936737060547),\n",
       " ('tweets', 0.8878158330917358),\n",
       " ('tl', 0.8778461217880249),\n",
       " ('link', 0.8778210878372192),\n",
       " ('internet', 0.8753897547721863)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사도 확인하기\n",
    "\n",
    "glove_vectors_25.most_similar(\"twitter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lady', 0.9231982827186584),\n",
       " ('called', 0.9227929711341858),\n",
       " (\"'s\", 0.9222200512886047),\n",
       " ('mother', 0.91953045129776),\n",
       " ('and', 0.9168232083320618),\n",
       " ('young', 0.9150474071502686),\n",
       " ('the', 0.9141177535057068),\n",
       " ('kid', 0.912209689617157),\n",
       " ('guy', 0.9105256199836731),\n",
       " ('child', 0.9063714742660522)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors_25.most_similar(positive=['woman', 'king'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 387.1/387.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "glove_vectors_100 = api.load('glove-twitter-100')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7052315473556519),\n",
       " ('prince', 0.6666139960289001),\n",
       " ('mother', 0.6436764597892761),\n",
       " ('royal', 0.6417251229286194),\n",
       " ('father', 0.5952689051628113),\n",
       " ('african', 0.5883978009223938),\n",
       " ('princess', 0.588217556476593),\n",
       " ('called', 0.5842776298522949),\n",
       " ('meets', 0.584027886390686),\n",
       " ('american', 0.5815179347991943)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors_100.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52202815"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glove_vectors_100.similar_by_word(\"cat\")\n",
    "glove_vectors_100.n_similarity(['sushi', 'shop'], ['japanese', 'restaruant'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_lecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "305494ec69d5ad97a583cc76e8fd52e450123bc765c435a27726a289dbe2d5e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
